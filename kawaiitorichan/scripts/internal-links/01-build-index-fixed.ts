#!/usr/bin/env tsx
/**
 * Build an index of posts with PROPER Japanese phrase extraction
 */

import { getPayload } from 'payload'
import configPromise from '@payload-config'
import * as fs from 'fs/promises'
import * as path from 'path'
import * as crypto from 'crypto'

const OUTPUT_DIR = path.join(process.cwd(), 'data', 'internal-links')

interface PostIndex {
  id: string
  title: string
  slug: string
  excerpt?: string
  keywords: string[]
  anchorPhrases: string[]
  contentHash: string
  language: 'ja' | 'en'
  textContent: string
}

/**
 * Properly extract text from Lexical editor format
 * This handles nested structures and preserves complete text
 */
function extractTextFromLexical(node: any, result: string[] = []): string {
  if (!node) return result.join('')
  
  // Handle text nodes
  if (node.type === 'text' && node.text) {
    result.push(node.text)
    return result.join('')
  }
  
  // Handle nodes with children
  if (node.children && Array.isArray(node.children)) {
    for (const child of node.children) {
      extractTextFromLexical(child, result)
    }
  }
  
  return result.join('')
}

/**
 * Universal metadata filter patterns
 */
const METADATA_PATTERNS = [
  // UI/Structure elements
  '„Éí„Éº„É≠„ÉºÁîªÂÉè', '„Ç¢„Ç§„Ç≠„É£„ÉÉ„ÉÅ', '„Çµ„É†„Éç„Ç§„É´', '„Ç§„É°„Éº„Ç∏ÁîªÂÉè',
  'Âá∫ÂÖ∏', 'ÂèÇËÄÉÊñáÁåÆ', '„É™„É≥„ÇØ:', 'ÁîªÂÉè:', '„ÇΩ„Éº„Çπ:',
  '„Ç≥„É°„É≥„Éà', '„Ç∑„Çß„Ç¢', '„ÅÑ„ÅÑ„Å≠', '„Éï„Ç©„É≠„Éº',

  // Navigation/UI
  'Ê¨°„Å∏', 'Ââç„Å∏', '„Éà„ÉÉ„Éó', '„Éõ„Éº„É†', '„É°„Éã„É•„Éº', '„Éö„Éº„Ç∏',
  '„ÇØ„É™„ÉÉ„ÇØ', '„Çø„ÉÉ„Éó', '„Çπ„ÇØ„É≠„Éº„É´', '„Ç∫„Éº„É†',

  // Time/Date patterns
  /^\d{4}Âπ¥\d{1,2}Êúà/, /^\d{1,2}Êúà\d{1,2}Êó•/, /^‰ªäÈÄ±/, /^ÂÖàÈÄ±/, /^Êù•ÈÄ±/,

  // Common unrelated terms (any domain)
  /^(Â∑û|Â∏Ç|Áî∫|Êùë)(Ë≠∞‰ºö|Èï∑|ÂΩπÊâÄ|ÊîøÂ∫ú)/, // Political terms
  /^(ÂãïÁîª|„Éì„Éá„Ç™|ÂÜôÁúü|Âõ≥|Ë°®|„Ç∞„É©„Éï|„ÉÅ„É£„Éº„Éà)/, // Media/visualization labels
  /^\[.*\]/, // Bracketed content (often metadata)

  // Reference/citation patterns
  /„É™„É≥„ÇØ$/, /„Éö„Éº„Ç∏$/, /„Çµ„Ç§„Éà$/,
]

/**
 * Check if a phrase is metadata/structural content
 */
function isMetadataPhrase(phrase: string): boolean {
  return METADATA_PATTERNS.some(pattern =>
    typeof pattern === 'string'
      ? phrase.includes(pattern)
      : pattern.test(phrase)
  )
}

/**
 * Common Japanese verb endings for proper phrase completion
 */
const VERB_ENDINGS = [
  '„Åô„Çã', '„Åó„Åü', '„Åó„Å¶', '„Åô„Çå„Å∞', '„Åó„Çà„ÅÜ', '„Åó„Åæ„Åô', '„Åó„Å™„ÅÑ', '„Åó„Åæ„Åó„Åü',
  '„Åè„Çã', '„Åç„Åü', '„Åç„Å¶', '„Åè„Çå„Å∞', '„Åì„Çà„ÅÜ', '„Åç„Åæ„Åô', '„Åì„Å™„ÅÑ', '„Åç„Åæ„Åó„Åü',
  '„ÅÑ„Çã', '„ÅÑ„Åü', '„ÅÑ„Å¶', '„ÅÑ„Çå„Å∞', '„ÅÑ„Çà„ÅÜ', '„ÅÑ„Åæ„Åô', '„ÅÑ„Å™„ÅÑ', '„ÅÑ„Åæ„Åó„Åü',
  '„ÅÇ„Çã', '„ÅÇ„Å£„Åü', '„ÅÇ„Å£„Å¶', '„ÅÇ„Çå„Å∞', '„ÅÇ„Çç„ÅÜ', '„ÅÇ„Çä„Åæ„Åô', '„Å™„ÅÑ', '„ÅÇ„Çä„Åæ„Åó„Åü',
  '„Åß„Åç„Çã', '„Åß„Åç„Åü', '„Åß„Åç„Å¶', '„Åß„Åç„Çå„Å∞', '„Åß„Åç„Çà„ÅÜ', '„Åß„Åç„Åæ„Åô', '„Åß„Åç„Å™„ÅÑ', '„Åß„Åç„Åæ„Åó„Åü',
  '„Å™„Çã', '„Å™„Å£„Åü', '„Å™„Å£„Å¶', '„Å™„Çå„Å∞', '„Å™„Çç„ÅÜ', '„Å™„Çä„Åæ„Åô', '„Å™„Çâ„Å™„ÅÑ', '„Å™„Çä„Åæ„Åó„Åü',
  '„Çå„Çã', '„Çâ„Çå„Çã', '„Åõ„Çã', '„Åï„Åõ„Çã', '„Çå„Åü', '„Çâ„Çå„Åü', '„Åõ„Åü', '„Åï„Åõ„Åü'
]

/**
 * Check if a phrase ends with a broken verb stem
 */
function isBrokenVerb(phrase: string): boolean {
  // Common patterns of truncated verbs
  const brokenPatterns = [
    /[^„Åß][„Åô„Åè]$/, // ends with „Åô or „Åè (but not „Åß„Åô)
    /[„ÅÑ„ÅÜ]$/, // ends with „ÅÑ or „ÅÜ (could be incomplete)
    /[„Å§„ÇÄ„Å∂„Å¨„Åê„Åö„Åò]$/ // other incomplete verb stems
  ]

  return brokenPatterns.some(pattern => pattern.test(phrase))
}

/**
 * Attempt to complete a broken verb phrase
 */
function completeVerb(phrase: string, fullText: string): string {
  // Look for the complete verb in the surrounding text
  for (const ending of VERB_ENDINGS) {
    const possibleComplete = phrase + ending.substring(phrase.length > 0 ? phrase[phrase.length - 1] === ending[0] ? 1 : 0 : 0)
    if (fullText.includes(possibleComplete)) {
      return possibleComplete
    }
  }

  // If no complete version found, try common completions
  if (phrase.endsWith('„Åô') && !phrase.endsWith('„Åß„Åô')) {
    return phrase + '„Çã'
  }
  if (phrase.endsWith('„Åè')) {
    return phrase + '„Çã'
  }

  return phrase // Return as-is if can't complete
}

/**
 * Extract meaningful Japanese phrases that make good anchor text (UNIVERSAL VERSION)
 */
function extractJapanesePhrases(text: string): string[] {
  const phrases = new Set<string>()
  
  // Clean the text
  const cleanText = text
    .replace(/<[^>]*>/g, ' ')
    .replace(/[\n\r]+/g, ' ')
    .replace(/\s+/g, ' ')
    .trim()
  
  // Extract compound nouns (katakana + kanji or kanji + katakana combinations)
  const compoundNouns = cleanText.match(/[„Ç°-„É∂„Éº]{2,}[‰∏Ä-Èæ†]{1,}|[‰∏Ä-Èæ†]{2,}[„Ç°-„É∂„Éº]{1,}/g)
  if (compoundNouns) {
    for (const compound of compoundNouns) {
      if (compound.length >= 3 && compound.length <= 12 && !isMetadataPhrase(compound)) {
        phrases.add(compound)
      }
    }
  }
  
  // Extract natural Japanese phrases from the text
  // Split by punctuation to get sentence fragments
  const sentences = cleanText.split(/[„ÄÇ„ÄÅÔºÅÔºü„Äå„Äç„Äé„ÄèÔºàÔºâ]/g)
  
  for (const sentence of sentences) {
    const trimmed = sentence.trim()
    if (!trimmed) continue
    
    // Look for noun phrases connected by particles
    // Pattern: [ÂêçË©û/ÂãïË©û]„ÅÆ[ÂêçË©û] (e.g., "„Çπ„Ç§„É≥„Ç∞„ÅÆÂü∫Êú¨")
    const nounPhrases = trimmed.match(/[„Ç°-„É∂„Éº‰∏Ä-Èæ†]{2,}[„ÅÆ„Å®„Åß][„Ç°-„É∂„Éº‰∏Ä-Èæ†]{2,}/g)
    if (nounPhrases) {
      for (const phrase of nounPhrases) {
        if (phrase.length >= 4 && phrase.length <= 15) {
          phrases.add(phrase)
        }
      }
    }
    
    // Look for compound katakana + kanji terms (universal pattern)
    const compoundTerms = trimmed.match(/[„Ç°-„É∂„Éº]{3,}[‰∏Ä-Èæ†]{1,4}/g)
    if (compoundTerms) {
      for (const term of compoundTerms) {
        if (term.length >= 4 && term.length <= 12 && !isMetadataPhrase(term)) {
          phrases.add(term)
        }
      }
    }
    
    // Look for complete verb phrases with proper endings
    const verbPhrases = trimmed.match(/[‰∏Ä-Èæ†]{2,}[„Çí„Åå„Å´][‰∏Ä-Èæ†]{2,}(„Åô„Çã|„Åè„Çã|„ÅÑ„Çã|„ÅÇ„Çã|„Åß„Åç„Çã|„Å™„Çã|„Çå„Çã|„Çâ„Çå„Çã|„Åõ„Çã|„Åï„Åõ„Çã|„Åó„Åü|„Åç„Åü|„ÅÑ„Åü|„ÅÇ„Å£„Åü|„Åß„Åç„Åü|„Å™„Å£„Åü|„Çå„Åü|„Çâ„Çå„Åü|„Åõ„Åü|„Åï„Åõ„Åü|„Åó„Å¶|„Åç„Å¶|„ÅÑ„Å¶|„ÅÇ„Å£„Å¶|„Åß„Åç„Å¶|„Å™„Å£„Å¶|„Çå„Å¶|„Çâ„Çå„Å¶|„Åõ„Å¶|„Åï„Åõ„Å¶)/g)
    if (verbPhrases) {
      for (const phrase of verbPhrases) {
        if (phrase.length >= 5 && phrase.length <= 15 && !isMetadataPhrase(phrase)) {
          phrases.add(phrase)
        }
      }
    }

    // Also look for potentially broken verb phrases and try to complete them
    const potentialVerbPhrases = trimmed.match(/[‰∏Ä-Èæ†]{2,}[„Çí„Åå„Å´][‰∏Ä-Èæ†]{2,}[„Åô„Åè„ÅÑ„ÅÜ„Å§„ÇÄ„Å∂„Å¨„Åê„Åö„Åò]/g)
    if (potentialVerbPhrases) {
      for (const phrase of potentialVerbPhrases) {
        if (phrase.length >= 5 && phrase.length <= 15 && !isMetadataPhrase(phrase)) {
          // Try to complete the verb
          const completed = completeVerb(phrase, cleanText)
          if (completed !== phrase) {
            phrases.add(completed)
          }
        }
      }
    }
    
    // Look for descriptive phrases (ÂΩ¢ÂÆπË©û + ÂêçË©û)
    const descriptivePhrases = trimmed.match(/[ËâØÊÇ™Ê≠£Á¢∫ÈÅ©ÂàáÂü∫Êú¨ÈáçË¶ÅÂ§ßÂ∞èÈ´ò‰ΩéÊó©ÈÅÖÂº∑Âº±][„ÅÑ„Åó„Åè„Åã„Å™]*[„Ç°-„É∂„Éº‰∏Ä-Èæ†]{2,}/g)
    if (descriptivePhrases) {
      for (const phrase of descriptivePhrases) {
        if (phrase.length >= 3 && phrase.length <= 10 && !isMetadataPhrase(phrase)) {
          phrases.add(phrase)
        }
      }
    }
  }
  
  // Extract meaningful standalone terms from the content itself (no hardcoding)
  // Look for terms that appear multiple times (likely important)
  const termCounts = new Map<string, number>()
  const termMatches = cleanText.match(/[„Ç°-„É∂„Éº‰∏Ä-Èæ†]{3,8}/g)
  if (termMatches) {
    for (const term of termMatches) {
      if (!isMetadataPhrase(term)) {
        termCounts.set(term, (termCounts.get(term) || 0) + 1)
      }
    }
  }

  // Add frequently occurring terms (appear 2+ times)
  for (const [term, count] of termCounts) {
    if (count >= 2 && term.length >= 3 && term.length <= 8) {
      phrases.add(term)
    }
  }
  
  // Filter and sort phrases
  const finalPhrases = Array.from(phrases)
    .filter(phrase => {
      // Remove single characters
      if (phrase.length < 2) return false
      // Remove phrases that are just particles
      if (/^[„ÅÆ„Åå„Çí„ÅØ„Åß„Å´„Å∏„Å®„ÇÇ]+$/.test(phrase)) return false
      // Keep everything else
      return true
    })
    // Sort by relevance: longer phrases first, then by frequency in text
    .sort((a, b) => {
      // Prioritize longer phrases (more specific)
      if (b.length !== a.length) return b.length - a.length

      // Then alphabetically
      return a.localeCompare(b)
    })
    .slice(0, 100) // Limit to top 100 phrases
  
  return finalPhrases
}

/**
 * Detect language of text
 */
function detectLanguage(text: string): 'ja' | 'en' {
  const japaneseChars = text.match(/[„ÅÅ-„Çì„Ç°-„É∂„Éº‰∏Ä-Èæ†]/g) || []
  const englishChars = text.match(/[a-zA-Z]/g) || []
  return japaneseChars.length > englishChars.length ? 'ja' : 'en'
}

/**
 * Generate content hash
 */
function generateContentHash(content: string): string {
  return crypto.createHash('md5').update(content).digest('hex')
}

async function buildIndex() {
  console.log('Building FIXED post index for internal linking...')
  
  const payload = await getPayload({ config: configPromise })
  
  try {
    // Fetch all published posts
    const { docs: posts } = await payload.find({
      collection: 'posts',
      limit: 1000,
      where: {
        _status: { equals: 'published' }
      },
      depth: 1 // Include related fields
    })
    
    console.log(`Found ${posts.length} published posts`)
    
    const indexedPosts: PostIndex[] = []
    
    for (const post of posts) {
      // Properly extract text from Lexical content
      const textContent = extractTextFromLexical(post.content?.root)
      const language = detectLanguage(textContent + ' ' + (post.title || ''))
      
      // Extract anchor phrases based on language
      let anchorPhrases: string[] = []
      if (language === 'ja') {
        anchorPhrases = extractJapanesePhrases(textContent + ' ' + (post.title || ''))
      }
      
      // Extract keywords from various sources
      const keywords: Set<string> = new Set()
      
      // Add title-based phrases
      if (post.title && language === 'ja') {
        const titlePhrases = extractJapanesePhrases(post.title)
        titlePhrases.forEach(phrase => keywords.add(phrase))
      }
      
      // Add SEO keywords if available
      if (post.meta?.keywords) {
        post.meta.keywords.split(',').forEach((kw: string) => {
          const cleaned = kw.trim()
          if (cleaned.length >= 2) keywords.add(cleaned)
        })
      }
      
      // Add category names
      if (post.categories && Array.isArray(post.categories)) {
        for (const cat of post.categories) {
          if (typeof cat === 'object' && cat.title) {
            keywords.add(cat.title)
          }
        }
      }
      
      const indexed: PostIndex = {
        id: String(post.id),
        title: post.title || '',
        slug: post.slug || '',
        excerpt: post.excerpt || '',
        keywords: Array.from(keywords),
        anchorPhrases: anchorPhrases,
        contentHash: generateContentHash(textContent),
        language,
        textContent: textContent.substring(0, 5000) // Store first 5000 chars for reference
      }
      
      indexedPosts.push(indexed)
      
      // Show sample phrases for debugging
      if (anchorPhrases.length > 0) {
        console.log(`‚úì ${post.title}`)
        console.log(`  Sample phrases: ${anchorPhrases.slice(0, 5).join(', ')}`)
      } else {
        console.log(`‚ö† ${post.title} (no phrases extracted)`)
      }
    }
    
    // Create output directory
    await fs.mkdir(OUTPUT_DIR, { recursive: true })
    
    // Save index
    const outputPath = path.join(OUTPUT_DIR, 'posts-index.json')
    await fs.writeFile(
      outputPath,
      JSON.stringify({ posts: indexedPosts, timestamp: new Date().toISOString() }, null, 2)
    )
    
    console.log('\n‚úÖ Index built successfully!')
    console.log(`üìÅ Saved to: ${outputPath}`)
    console.log(`üìä Total posts indexed: ${indexedPosts.length}`)
    
    // Statistics
    const japanesePosts = indexedPosts.filter(p => p.language === 'ja')
    const withPhrases = japanesePosts.filter(p => p.anchorPhrases.length > 0)
    const avgPhrases = japanesePosts.reduce((sum, p) => sum + p.anchorPhrases.length, 0) / Math.max(japanesePosts.length, 1)
    
    console.log('\nüìà Statistics:')
    console.log(`  - Japanese posts: ${japanesePosts.length}`)
    console.log(`  - Posts with phrases: ${withPhrases.length}`)
    console.log(`  - Avg phrases per Japanese post: ${Math.round(avgPhrases)}`)
    
  } catch (error) {
    console.error('‚ùå Error building index:', error)
    process.exit(1)
  }
  
  process.exit(0)
}

buildIndex().catch(console.error)